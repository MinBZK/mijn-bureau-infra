ai:
  llm:
    model: ~
    endpoint:
      host: ~
      port: ~
      path: "v1"
      isSsl: true
      isInternal: false
    apiKey: ~
